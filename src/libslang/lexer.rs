use logos::{Logos, SpannedIter};

use std::fmt;

#[derive(Default, Debug, Clone, PartialEq)]
pub enum LexingError {
    ParseNumberError,
    #[default]
    InvalidToken,
}

impl fmt::Display for LexingError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
      write!(f, "{:?}", self)
    }
}

impl From<std::num::ParseIntError> for LexingError {
    fn from(_: std::num::ParseIntError) -> Self {
        LexingError::ParseNumberError
    }
}

impl From<std::num::ParseFloatError> for LexingError {
    fn from(_: std::num::ParseFloatError) -> Self {
        LexingError::ParseNumberError
    }
}

/// The tokens that slang can have. The lexer is auto-generated by
/// `logos`. High priorities are assigned to keywords and symbols 
/// so they are matched before identifiers and numbers.
#[derive(Logos, Debug, PartialEq)]
#[logos(error = LexingError)]
#[logos(subpattern decimal = r"[0-9][_0-9]*")]
#[logos(subpattern hex = r"[0-9a-fA-F][_0-9a-fA-F]*")]
#[logos(subpattern octal = r"[0-7][_0-7]*")]
#[logos(subpattern binary = r"[0-1][_0-1]*")]
#[logos(skip r"(//[^\\n].*)|([ \t\n\f]+)")]
pub enum Token {
    // Single character symbols
    #[token(":", priority = 500)]
    Colon,

    #[token(",", priority = 501)]
    Comma,

    #[token(".", priority = 502)]
    Dot,

    #[token("{", priority = 503)]
    LBrace,

    #[token("}", priority = 504)]
    RBrace,

    #[token("(", priority = 505)]
    LParen,

    #[token(")", priority = 506)]
    RParen,

    #[token("[", priority = 507)]
    LBracket,

    #[token("]", priority = 508)]
    RBracket,

    #[token(";", priority = 509)]
    Semicolon,


    // Comparison and assignment operators
    #[token("!", priority = 510)]
    Bang,

    #[token("!=", priority = 511)]
    BangEq,

    #[token("=", priority = 512)]
    Eq,

    #[token("==", priority = 513)]
    EqEq,

    #[token(">", priority = 514)]
    Gt,

    #[token(">=", priority = 515)]
    Gte,

    #[token("<", priority = 516)]
    Lt,

    #[token("<=", priority = 517)]
    Lte,


    // Arithmetic
    #[token("+", priority = 518)]
    Plus,

    #[token("++", priority = 519)]
    PlusPlus,

    #[token("+=", priority = 520)]
    PlusEq,

    #[token("-", priority = 521)]
    Minus,

    #[token("--", priority = 522)]
    MinusMinus,

    #[token("-=", priority = 523)]
    MinusEq,

    #[token("/", priority = 526)]
    Slash,

    #[token("/=", priority = 527)]
    SlashEq,

    #[token("*", priority = 524)]
    Star,

    #[token("*=", priority = 525)]
    StarEq,


    // Keywords
    #[token("and", priority = 1000)]
    And,

    #[token("break", priority = 1001)]
    Break,

    #[token("clone", priority = 1002)]
    Clone,

    #[token("const", priority = 1003)]
    Const,

    #[token("continue", priority = 1004)]
    Continue,

    #[token("else", priority = 1005)]
    Else,

    #[token("none", priority = 1006)]
    None,

    #[token("false", priority = 1007)]
    False,

    #[token("fn", priority = 1008)]
    Fn,

    #[token("for", priority = 1009)]
    For,

    #[token("if", priority = 1010)]
    If,

    #[token("let", priority= 1011)]
    Let,

    #[token("or", priority = 1012)]
    Or,

    #[token("print", priority = 1013)]
    Print,

    #[token("ret", priority = 1014)]
    Ret,

    #[token("self", priority = 1015)]
    Slf,

    #[token("true", priority = 1016)]
    True,

    #[token("while", priority = 1017)]
    While,

    // Integers and identifiers
    // Strip quotes from beginning and end
    #[regex("_?[a-zA-Z_][a-zA-Z0-9_]*", priority = 6, callback = |lex| lex.slice().to_string())]
    Identifier(String),

    #[regex("-?[0-9]+\\.[0-9]+", priority = 11, callback = |lex| lex.slice().parse())]
    Float(f64),
    
    // // Integer matching.
    #[regex(r"(-?(?&decimal))|(0[xX](?&hex))|(0[oO](?&octal))|(0[bB](?&binary))", priority = 10, callback = parse_num)]
    Int(i64),

    // Matches a double quote string or a single quote string
    #[regex(r#""([^\\"]|\\t|\\n|\\")*"|'([^\\']|\\t|\\n|\\')*'"#, priority = 5, callback = |lex| lex.slice().strip_prefix(|c| c == '"' || c == '\'').unwrap().strip_suffix(|c| c == '"' || c == '\'').unwrap().to_string())]
    String(String),

}

fn parse_num(lex: &mut logos::Lexer<Token>) -> Option<i64> {
    let slice = lex.slice().replace("_", "");

    if slice.chars().nth(0)? == '0' && slice.len() > 1 {
        match slice.chars().nth(1) {
            Some('x') | Some('X') => Some(i64::from_str_radix(&slice[2..], 16).ok()?),
            Some('o') | Some('O') => Some(i64::from_str_radix(&slice[2..], 8).ok()?),
            Some('b') | Some('B') => Some(i64::from_str_radix(&slice[2..], 2).ok()?),
            _ => None
        }
    } else {
        Some(slice.parse().ok()?)
    }
}

impl fmt::Display for Token {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
      write!(f, "{:?}", self)
    }
}

pub type Spanned<Tok, Loc, Error> = Result<(Loc, Tok, Loc), Error>;

/// Lexer used LALRPOP. It depends on the lexer that's
/// generated by LALRPOP. This is just a wrapper around that.
pub struct Lexer<'input> {
    token_stream: SpannedIter<'input, Token>,
}

impl<'input> Lexer<'input> {
    pub fn new(input: &'input str) -> Self {
        Self { token_stream: Token::lexer(input).spanned() }
    }
}

impl<'input> Iterator for Lexer<'input> {
    type Item = Spanned<Token, usize, LexingError>;

    fn next(&mut self) -> Option<Self::Item> {
        self.token_stream.next().map(|(token, span)| {
            match token {
                Err(err) => Err(err),
                Ok(tok) => Ok((span.start, tok, span.end)),
            }
        })
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    // Generates tests for checking individual tokens
    macro_rules! gen_test {
        ($name: ident, $input: expr, $expected_res: expr) => {
            #[test]
            fn $name() {
                let mut lex = Token::lexer($input);
                
                assert_eq!(lex.next(), Some(Ok($expected_res)));
                assert_eq!(lex.slice(), $input);
                assert_eq!(lex.next(), None);
            }
        }
    }

    // TODO: Add tests with multiple strings

    gen_test!(test_dot, ".", Token::Dot);
    gen_test!(test_comma, ",", Token::Comma);
    gen_test!(test_lbrace, "{", Token::LBrace);
    gen_test!(test_rbrace, "}", Token::RBrace);
    gen_test!(test_lparen, "(", Token::LParen);
    gen_test!(test_rparen, ")", Token::RParen);
    gen_test!(test_lbracket, "[", Token::LBracket);
    gen_test!(test_rbracket, "]", Token::RBracket);
    gen_test!(test_semicolon, ";", Token::Semicolon);

    gen_test!(test_bang, "!", Token::Bang);
    gen_test!(test_bangeq, "!=", Token::BangEq);
    gen_test!(test_eq, "=", Token::Eq);
    gen_test!(test_eqeq, "==", Token::EqEq);
    gen_test!(test_gt, ">", Token::Gt);
    gen_test!(test_gte, ">=", Token::Gte);
    gen_test!(test_lt, "<", Token::Lt);
    gen_test!(test_lte, "<=", Token::Lte);

    gen_test!(test_plus, "+", Token::Plus);
    gen_test!(test_plusplus, "++", Token::PlusPlus);
    gen_test!(test_pluseq, "+=", Token::PlusEq);
    gen_test!(test_minus, "-", Token::Minus);
    gen_test!(test_minusminus, "--", Token::MinusMinus);
    gen_test!(test_slash, "/", Token::Slash);
    gen_test!(test_slasheq, "/=", Token::SlashEq);
    gen_test!(test_star, "*", Token::Star);
    gen_test!(test_stareq, "*=", Token::StarEq);

    gen_test!(test_and, "and", Token::And);
    gen_test!(test_break, "break", Token::Break);
    gen_test!(test_clone, "clone", Token::Clone);
    gen_test!(test_const, "const", Token::Const);
    gen_test!(test_continue, "continue", Token::Continue);
    gen_test!(test_else, "else", Token::Else);
    gen_test!(test_none, "none", Token::None);
    gen_test!(test_false, "false", Token::False);
    gen_test!(test_fn, "fn", Token::Fn);
    gen_test!(test_for, "for", Token::For);
    gen_test!(test_if, "if", Token::If);
    gen_test!(test_let, "let", Token::Let);
    gen_test!(test_or, "or", Token::Or);
    gen_test!(test_print, "print", Token::Print);
    gen_test!(test_ret, "ret", Token::Ret);
    gen_test!(test_slf, "self", Token::Slf);
    gen_test!(test_true, "true", Token::True);
    gen_test!(test_while, "while", Token::While);

    gen_test!(test_int_123, "123", Token::Int(123));
    gen_test!(test_int_negative_123, "-123", Token::Int(-123));
    gen_test!(test_int_1_2_3, "1_2_3", Token::Int(1_2_3));
    gen_test!(test_int_negative_1_2_3, "-1_2_3", Token::Int(-1_2_3));
    gen_test!(test_int_12_3, "12_3", Token::Int(12_3));
    gen_test!(test_float_123_123, "123.123", Token::Float(123.123));

    gen_test!(test_oct_0o123, "0o123", Token::Int(0o123));
    gen_test!(test_oct_0capo123, "0O123", Token::Int(0o123));
    gen_test!(test_oct_0o1_2_3, "0o1_2_3", Token::Int(0o1_2_3));

    gen_test!(test_binary_0b101, "0b101", Token::Int(0b101));
    gen_test!(test_binary_0capb101, "0B101", Token::Int(0b101));
    gen_test!(test_binary_0b1_0_1, "0b101", Token::Int(0b1_0_1));

    gen_test!(test_hex_0x123f, "0x123f", Token::Int(0x123f));
    gen_test!(test_hex_0capx123, "0X123f", Token::Int(0x123f));
    gen_test!(test_hex_0x12_3_f, "0x12_3_f", Token::Int(0x12_3_f));

    gen_test!(test_identifier_abc, "abc", Token::Identifier("abc".to_string()));
    gen_test!(test_identifier_und_abc, "_abc", Token::Identifier("_abc".to_string()));
    gen_test!(test_identifier_und_und_abc, "__abc", Token::Identifier("__abc".to_string()));
    gen_test!(test_identifier_und_und_und_abc, "___abc", Token::Identifier("___abc".to_string()));
    gen_test!(test_identifier_und_abc1, "_abc1", Token::Identifier("_abc1".to_string()));
    gen_test!(test_identifier_und_abc1abc, "_abc1abc", Token::Identifier("_abc1abc".to_string()));
    gen_test!(test_identifier_und_abc_und_1abc, "_abc_1abc", Token::Identifier("_abc_1abc".to_string()));
    gen_test!(test_identifier_und_abc1_abc, "_abc1_abc", Token::Identifier("_abc1_abc".to_string()));
    gen_test!(test_identifier_und_a1, "_a1", Token::Identifier("_a1".to_string()));
    gen_test!(test_identifier_und_a1_und, "_a1_", Token::Identifier("_a1_".to_string()));
    gen_test!(test_identifier_und_abc_und, "_abc_", Token::Identifier("_abc_".to_string()));
    gen_test!(test_identifier_und_abc_und_abc, "_abc_abc", Token::Identifier("_abc_abc".to_string()));
    gen_test!(test_identifier_und_and, "_and", Token::Identifier("_and".to_string()));

    gen_test!(test_string_dq_abc, r#""abc""#, Token::String("abc".to_string()));
    gen_test!(test_string_dq_abc_backslashdq, r#""abc\"""#, Token::String(r#"abc\""#.to_string()));
    gen_test!(test_string_dq_abc_backslashdq_backslashdq, r#""abc\"\"""#, Token::String(r#"abc\"\""#.to_string()));

    gen_test!(test_string_dq_abc_backslashn, r#""abc\n""#, Token::String(r#"abc\n"#.to_string()));
    gen_test!(test_string_dq_abc_backslashn_backslashn, r#""abc\n\n""#, Token::String(r#"abc\n\n"#.to_string()));

    gen_test!(test_string_dq_abc_backslasht, r#""abc\t""#, Token::String(r#"abc\t"#.to_string()));
    gen_test!(test_string_dq_abc_backslasht_backslasht, r#""abc\t\t""#, Token::String(r#"abc\t\t"#.to_string()));

    gen_test!(test_string_sq_abc, r#"'abc'"#, Token::String("abc".to_string()));
    gen_test!(test_string_sq_abc_backslashsq, r#"'abc\''"#, Token::String(r#"abc\'"#.to_string()));
    gen_test!(test_string_sq_abc_backslashsq_backslashsq, r#"'abc\'\''"#, Token::String(r#"abc\'\'"#.to_string()));

    gen_test!(test_string_sq_abc_backslashn, r#"'abc\n'"#, Token::String(r#"abc\n"#.to_string()));
    gen_test!(test_string_sq_abc_backslashn_backslashn, r#"'abc\n\n'"#, Token::String(r#"abc\n\n"#.to_string()));

    gen_test!(test_string_sq_abc_backslasht, r#"'abc\t'"#, Token::String(r#"abc\t"#.to_string()));
    gen_test!(test_string_sq_abc_backslasht_backslasht, r#"'abc\t\t'"#, Token::String(r#"abc\t\t"#.to_string()));

    #[test]
    fn test_comment() {
        let mut lex = Token::lexer("// This is a comment");

        assert_eq!(lex.next(), None);
    }

    #[test]
    fn test_whitespace() {
        let mut lex = Token::lexer("12 clone\tabc");

        assert_eq!(lex.next(), Some(Ok(Token::Int(12))));
        assert_eq!(lex.next(), Some(Ok(Token::Clone)));
        assert_eq!(lex.next(), Some(Ok(Token::Identifier("abc".to_string()))));
        assert_eq!(lex.next(), None);
    }
}
